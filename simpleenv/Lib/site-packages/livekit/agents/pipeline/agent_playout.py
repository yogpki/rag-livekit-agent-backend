from __future__ import annotations

import asyncio
from typing import AsyncIterable, Literal

from livekit import rtc

from .. import transcription, utils
from .log import logger

from collections import deque

import sys
import os

# 添加包含 audio2face_pb2 和 audio2face_pb2_grpc 的目录到 Python 的模块搜索路径
sys.path.append(r'C:\Users\Yoki\Desktop\sumatra\_gpgit\rag-livekit-agent-backend\a2f')

import time
import audio2face_pb2
import audio2face_pb2_grpc
import grpc
import numpy as np
import io
import soundfile as sf

# Constants for Audio2Face
A2F_URL = "localhost:50051"
INSTANCE_NAME = "/World/audio2face/PlayerStreaming"

CHUNK_SIZE_BY = 10



EventTypes = Literal["playout_started", "playout_stopped"]


class PlayoutHandle:
    def __init__(
        self,
        speech_id: str,
        audio_source: rtc.AudioSource,
        playout_source: AsyncIterable[rtc.AudioFrame],
        transcription_fwd: transcription.TTSSegmentsForwarder,
    ) -> None:
        self._playout_source = playout_source
        self._audio_source = audio_source
        self._tr_fwd = transcription_fwd
        self._interrupted = False
        self._int_fut = asyncio.Future[None]()
        self._done_fut = asyncio.Future[None]()
        self._speech_id = speech_id
        self._pushed_duration = 0.0
        self._total_played_time: float | None = None  # set whem the playout is done

    @property
    def speech_id(self) -> str:
        return self._speech_id

    @property
    def interrupted(self) -> bool:
        return self._interrupted

    @property
    def time_played(self) -> float:
        if self._total_played_time is not None:
            return self._total_played_time

        return self._pushed_duration - self._audio_source.queued_duration

    def done(self) -> bool:
        return self._done_fut.done() or self._interrupted

    def interrupt(self) -> None:
        if self.done():
            return

        self._int_fut.set_result(None)
        self._interrupted = True

    def join(self) -> asyncio.Future:
        return self._done_fut


class AgentPlayout(utils.EventEmitter[EventTypes]):
    def __init__(self, *, audio_source: rtc.AudioSource) -> None:
        super().__init__()
        self._audio_source = audio_source
        self._target_volume = 1.0
        self._playout_atask: asyncio.Task[None] | None = None
        self._closed = False

       

    

    async def push_audio_track_stream(self, url, audio_data, samplerate, instance_name):
        
        chunk_size = samplerate // CHUNK_SIZE_BY
        sleep_between_chunks = 0.04  # in seconds
        block_until_playback_is_finished = True


        async with grpc.aio.insecure_channel(url) as channel:  # Use async gRPC channel
            print("Async Channel created")

            stub = audio2face_pb2_grpc.Audio2FaceStub(channel)

            async def make_generator():
                
                start_marker = audio2face_pb2.PushAudioRequestStart(
                    samplerate=samplerate,
                    instance_name=instance_name,
                    block_until_playback_is_finished=block_until_playback_is_finished,
                )
                
                yield audio2face_pb2.PushAudioStreamRequest(start_marker=start_marker)
                
                for i in range(0, len(audio_data), chunk_size):
                    await asyncio.sleep(sleep_between_chunks)
                    chunk = audio_data[i: i + chunk_size]
                    yield audio2face_pb2.PushAudioStreamRequest(audio_data=chunk.astype(np.float32).tobytes())

            request_generator = make_generator()
            print("Sending audio data...")
            try:
                response = await stub.PushAudioStream(request_generator)
                if response.success:
                    print("SUCCESS")
                else:
                    print(f"ERROR: {response.message}")
            except grpc.RpcError as e:
                print(f"gRPC error: {e}")
        
        print("Async Channel closed")
        



    @property
    def target_volume(self) -> float:
        return self._target_volume

    @target_volume.setter
    def target_volume(self, value: float) -> None:
        self._target_volume = value

    @property
    def smoothed_volume(self) -> float:
        return self._target_volume

    async def aclose(self) -> None:
        if self._closed:
            return

        self._closed = True

        if self._playout_atask is not None:
            await self._playout_atask

    def play(
        self,
        speech_id: str,
        playout_source: AsyncIterable[rtc.AudioFrame],
        transcription_fwd: transcription.TTSSegmentsForwarder,
    ) -> PlayoutHandle:
        if self._closed:
            raise ValueError("cancellable source is closed")

        handle = PlayoutHandle(
            speech_id=speech_id,
            audio_source=self._audio_source,
            playout_source=playout_source,
            transcription_fwd=transcription_fwd,
        )
        self._playout_atask = asyncio.create_task(
            self._playout_task(self._playout_atask, handle)
        )

        return handle
    
    

    @utils.log_exceptions(logger=logger)
    async def _playout_task(
        self, old_task: asyncio.Task[None] | None, handle: PlayoutHandle
    ) -> None:
        if old_task is not None:
            await utils.aio.gracefully_cancel(old_task)

        if self._audio_source.queued_duration > 0:
            logger.warning(
                "new playout while the source is still playing",
                extra={
                    "speech_id": handle.speech_id,
                    "queued_duration": self._audio_source.queued_duration,
                },
            )

        first_frame = True

        @utils.log_exceptions(logger=logger)
        async def _capture_task():
            nonlocal first_frame
            audio_buffer = deque()

            async def audio_generator():
                nonlocal first_frame

                # 初始化並發送 start marker 只在首次幀時進行
                if first_frame:
                    start_marker = audio2face_pb2.PushAudioRequestStart(
                        samplerate=24000,
                        instance_name=INSTANCE_NAME,
                        block_until_playback_is_finished=True,
                    )
                    yield audio2face_pb2.PushAudioStreamRequest(start_marker=start_marker)
                    logger.debug("Start marker sent")
                    first_frame = False

                async for frame in handle._playout_source:
                    # 將音頻數據加入緩衝區
                    audio_data = np.frombuffer(frame.data, dtype=np.int16).astype(np.float32) / 32768.0
                    audio_buffer.extend(audio_data)
                    # logger.debug(
                    #     "Audio data added to buffer",
                    #     extra={"speech_id": handle.speech_id, "buffer_length": len(audio_buffer)}
                    # )

                    # 每當緩衝區數據達到 chunk 大小時，發送音頻塊
                    chunk_size = frame.sample_rate // CHUNK_SIZE_BY
                    while len(audio_buffer) >= chunk_size:
                        chunk = np.array([audio_buffer.popleft() for _ in range(chunk_size)], dtype=np.float32)
                        yield audio2face_pb2.PushAudioStreamRequest(audio_data=chunk.tobytes())
                        # logger.debug(
                        #     "Audio chunk sent",
                        #     extra={"speech_id": handle.speech_id, "chunk_size": chunk_size}
                        # )

                # 檢查是否有剩餘音頻數據，若有則發送剩餘數據
                if audio_buffer:
                    remaining_chunk = np.array(list(audio_buffer), dtype=np.float32)
                    yield audio2face_pb2.PushAudioStreamRequest(audio_data=remaining_chunk.tobytes())
                    logger.debug(
                        "Remaining audio chunk sent",
                        extra={"speech_id": handle.speech_id, "remaining_chunk_size": len(remaining_chunk)},
                    )

            # 發送音頻流並處理伺服器回應
            async with grpc.aio.insecure_channel(A2F_URL) as channel:
                logger.debug("Async Channel created for streaming")
                stub = audio2face_pb2_grpc.Audio2FaceStub(channel)
                try:
                    # 因為 `PushAudioStream` 是 StreamUnaryCall，所以用 `await` 而不是 `async for`
                    response = await stub.PushAudioStream(audio_generator())
                    if response.success:
                        logger.debug("Server acknowledged audio stream", extra={"server_message": response.message})
                    else:
                        logger.error("Server reported an error", extra={"server_message": response.message})
                except grpc.aio.AioRpcError as e:  # 使用 AioRpcError 處理異常
                    logger.error("gRPC streaming error", extra={"error": str(e)})

                logger.debug("Async Channel closed")  # 確保通道已關閉

        capture_task = asyncio.create_task(_capture_task())
        try:
            await asyncio.wait(
                [capture_task, handle._int_fut],
                return_when=asyncio.FIRST_COMPLETED,
            )
        finally:
            await utils.aio.gracefully_cancel(capture_task)
            handle._total_played_time = (
                handle._pushed_duration - self._audio_source.queued_duration
            )

            if handle.interrupted or capture_task.exception():
                self._audio_source.clear_queue()  # 確保移除排隊的幀

            if not first_frame:
                if not handle.interrupted:
                    handle._tr_fwd.segment_playout_finished()

                self.emit("playout_stopped", handle.interrupted)

            await handle._tr_fwd.aclose()
            handle._done_fut.set_result(None)

            logger.debug(
                "Speech playout finished",
                extra={
                    "speech_id": handle.speech_id,
                    "interrupted": handle.interrupted,
                },
            )